import base64
import copy
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from threading import Lock
from typing import Any

import alibabacloud_oss_v2 as oss
from pydantic import validate_call
from tqdm import tqdm

from .Auth import Auth
from .File import File
from .model.Base import UserInfoModel
from .model.model import FileUploadParams
from .utils.Constants import API
from .utils.sha import calc_sha1, calc_sha1_range, calc_sign_val


class Uploader:
    """æ–‡ä»¶ä¸Šä¼ æ“ä½œå°è£…"""

    def __init__(self, auth: Auth, userinfo: UserInfoModel | None = None):
        """åˆå§‹åŒ–

        Args:
            auth: å·²æˆæƒçš„ Auth å®ä¾‹
        """

        self.auth = auth
        self.userinfo = userinfo
        self.file = File(auth, userinfo)
        self._counter = 0
        self._counter_lock = Lock()  # ä¿æŠ¤ counter çš„çº¿ç¨‹é”

    @validate_call
    def get_token(self) -> dict:
        """è·å–ä¸Šä¼ Token

        è·å–ä¸Šä¼ æ–‡ä»¶æ‰€éœ€çš„Tokenä¿¡æ¯

        å‚è€ƒæ¥å£æ–‡æ¡£:  [/open/upload/get_token](https://www.yuque.com/115yun/open/kzacvzl0g7aiyyn4)


        Returns:
            åŒ…å«ä¸Šä¼ Tokenä¿¡æ¯

        """
        resp = self.auth.request_json("GET", API.FilePath.UPLOAD_TOKEN)
        return resp

    @validate_call
    def init(
        self,
        file_name: str,
        file_size: int | None = None,
        target: str | int = "0",
        fileid: str | None = None,
        preid: str | None = None,
        pick_code: str | None = None,
        topupload: int | None = None,
        sign_key: str | None = None,
        sign_val: str | None = None,
    ) -> tuple[dict, dict]:
        """æ–‡ä»¶ä¸Šä¼ 

        æ–­ç‚¹ç»­ä¼ ä¸Šä¼ åˆå§‹åŒ–è°ƒåº¦æ¥å£

        å‚è€ƒæ¥å£æ–‡æ¡£: [/open/upload/init](https://www.yuque.com/115yun/open/ul4mrauo5i2uza0q)

        Args:
            file_name:      æ–‡ä»¶å
            file_size:      æ–‡ä»¶å¤§å°(å­—èŠ‚)
            target:         æ–‡ä»¶ä¸Šä¼ ç›®æ ‡çº¦å®š, æ–‡ä»¶å¤¹ID
            fileid:        æ–‡ä»¶sha1å€¼
            preid:        æ–‡ä»¶å‰128Ksha1
            pick_code:    ä¸Šä¼ ä»»åŠ¡key[éç§’ä¼ çš„è°ƒåº¦æ¥å£è¿”å›çš„pick_codeå­—æ®µ]
            topupload:    ä¸Šä¼ è°ƒåº¦æ–‡ä»¶ç±»å‹è°ƒåº¦æ ‡è®°
            sign_key:     äºŒæ¬¡è®¤è¯éœ€è¦
            sign_val:     äºŒæ¬¡è®¤è¯éœ€è¦(å¤§å†™)

        Returns:
            tuple[dict, dict]: åŒ…å«æ¥å£è¿”å›çš„ JSON å’Œä¸Šä¼ åˆå§‹åŒ–å‚æ•°ï¼Œè¿”å› (resp, fileinfo)

                - resp: æ¥å£è¿”å›çš„ JSON
                - fileinfo: ä¸Šä¼ çš„å‚æ•°

        """
        # å¦‚æœä¼ å…¥çš„æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œé¿å…é‡å¤è°ƒç”¨ Path() å¹¶åªåšä¸€æ¬¡æ–‡ä»¶å­˜åœ¨æ£€æŸ¥
        p = Path(file_name)
        is_local_file = p.is_file()

        # ä»æœ¬åœ°æ–‡ä»¶è¡¥å…¨ç¼ºå¤±çš„ä¿¡æ¯ï¼ˆä»…åœ¨ä¼ å…¥æœ¬åœ°è·¯å¾„æ—¶ï¼‰
        if is_local_file:
            file_size = p.stat().st_size if file_size is None else file_size
            fileid = calc_sha1(str(p)) if fileid is None else fileid
            preid = calc_sha1_range(str(p), 0, 128 * 1024 - 1) if preid is None else preid
            # æå–çº¯æ–‡ä»¶åä½œä¸ºäº‘ç«¯æ–‡ä»¶åï¼ˆä¸åŒ…å«è·¯å¾„ï¼‰
            cloud_file_name = p.name
        else:
            # å¦‚æœä¸æ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œå‡å®š file_name å°±æ˜¯äº‘ç«¯æ–‡ä»¶å
            cloud_file_name = file_name

        # sign_key å’Œ sign_val å¿…é¡»åŒæ—¶æä¾›æˆ–åŒæ—¶ä¸º None
        if (sign_key is None) ^ (sign_val is None):
            raise ValueError("sign_key å’Œ sign_val å¿…é¡»åŒæ—¶æä¾›æˆ–åŒæ—¶ä¸º None")

        if file_size is None or file_size <= 0:
            raise ValueError("file_size å‚æ•°ä¸èƒ½ä¸ºç©ºï¼Œä¸”å¿…é¡»ä¸ºæ­£æ•´æ•°")

        if not fileid:
            raise ValueError("fileid å‚æ•°ä¸èƒ½ä¸ºç©º")

        # ä½¿ç”¨ pydantic æ¨¡å‹è¿›è¡Œå‚æ•°æ ¡éªŒä¸è§„èŒƒåŒ–
        params = FileUploadParams(
            file_name=cloud_file_name,  # ä½¿ç”¨æå–çš„çº¯æ–‡ä»¶å
            file_size=file_size,
            target=target,
            fileid=fileid,
            preid=preid,
            pick_code=pick_code,
            topupload=topupload,
            sign_key=sign_key,
            sign_val=sign_val,
        )

        fileinfo = params.model_dump(exclude_none=True)

        resp = self.auth.request_json("POST", API.FilePath.UPLOAD_INIT, data=fileinfo)
        data = self._extract_data(resp)
        status = data.get("status")
        sign_key = data.get("sign_key", "")
        if (status == 2 and sign_key == "") or status == 1:
            # åªæœ‰ç§’ä¼ ,ä¸”ä¸éœ€è¦äºŒæ¬¡è®¤è¯æ—¶æ‰æ‰“å°æ—¥å¿—
            with self._counter_lock:
                self._counter += 1
                # print("---------------------------------")
                # print(f"ç¬¬{self._counter}æ¬¡ä¸Šä¼ ")
                # print(f"ä¸Šä¼ åˆå§‹åŒ–å‚æ•°: {json.dumps(fileinfo, ensure_ascii=False, indent=2)}")
                # print("---------------------------------")
        return resp, fileinfo

    @validate_call
    def resume(self, file_size: int, fileid: str, pick_code: str, *, target: int | str = 0) -> dict:
        """æ–­ç‚¹ç»­ä¼ åˆå§‹åŒ–ï¼ˆ

        æ–­ç‚¹ç»­ä¼ ä¸Šä¼ ç»­ä¼ è°ƒåº¦æ¥å£

        å‚è€ƒæ¥å£æ–‡æ¡£: [/open/upload/resume](https://www.yuque.com/115yun/open/tzvi9sbcg59msddz)

        Args:
            file_size: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            target: ä¸Šä¼ ç›®æ ‡ï¼Œæ”¯æŒ 'U_1_0' æˆ–æ–‡ä»¶å¤¹ID
            fileid: æ–‡ä»¶ sha1 å€¼
            pick_code: ä¸Šä¼ ä»»åŠ¡ keyï¼ˆç»­ä¼ æ—¶å¿…éœ€ï¼‰

        Returns:
            dict: æ¥å£è¿”å›çš„ JSON
        """
        if not str(target).startswith("U_1_"):
            target = f"U_1_{target}"

        data = {"file_size": file_size, "target": target, "fileid": fileid, "pick_code": pick_code}
        resp = self.auth.request_json("POST", API.FilePath.UPLOAD_RESUME, data=data)
        return resp

    @validate_call
    def init_with_auto_sign(
        self,
        file_name: str,
        file_size: int | None = None,
        target: str | int = "0",
        fileid: str | None = None,
        preid: str | None = None,
        pick_code: str | None = None,
        topupload: int | None = None,
    ) -> dict:
        """è°ƒç”¨ init å¹¶åœ¨éœ€è¦äºŒæ¬¡è®¤è¯æ—¶è‡ªåŠ¨è®¡ç®—å¹¶æäº¤ sign_val

        è°ƒç”¨ init æ¥å£ï¼Œå¹¶åœ¨éœ€è¦äºŒæ¬¡è®¤è¯æ—¶è‡ªåŠ¨è®¡ç®— sign_val å¹¶é‡æ–°è°ƒç”¨ init æ¥å£

        Args:
            file_name:      æ–‡ä»¶å
            file_size:      æ–‡ä»¶å¤§å°(å­—èŠ‚)
            target:         æ–‡ä»¶ä¸Šä¼ ç›®æ ‡çº¦å®š, æ–‡ä»¶å¤¹ID
            fileid:        æ–‡ä»¶sha1å€¼
            preid:        æ–‡ä»¶å‰128Ksha1
            pick_code:    ä¸Šä¼ ä»»åŠ¡key[éç§’ä¼ çš„è°ƒåº¦æ¥å£è¿”å›çš„pick_codeå­—æ®µ]
            topupload:    ä¸Šä¼ è°ƒåº¦æ–‡ä»¶ç±»å‹è°ƒåº¦æ ‡è®°

        Returns:
            å“åº”æ•°æ®


        """
        resp, fileinfo = self.init(
            file_name=file_name,
            file_size=file_size,
            target=target,
            fileid=fileid,
            preid=preid,
            pick_code=pick_code,
            topupload=topupload,
        )
        item = self._extract_data(resp)

        status = item.get("status")
        code = item.get("code") or resp.get("code")

        # ç§’ä¼ æˆåŠŸ
        if status == 2:
            return resp

        # åˆ¤æ–­æ˜¯å¦éœ€è¦äºŒæ¬¡è®¤è¯
        sign_check = str(item.get("sign_check"))
        sign_key = str(item.get("sign_key"))
        if (status in {6, 7, 8} or code in {700, 701, 702}) and sign_check and sign_key:
            fileinfo["sign_key"] = sign_key
            fileinfo["sign_val"] = calc_sign_val(file_name, sign_check)

            # ç¬¬äºŒæ¬¡å¸¦ç­¾åçš„ init
            resp2, fileinfo2 = self.init(**fileinfo)
            return resp2

        return resp

    # ---------- ä¸Šä¼ åˆ° OSS(åªæ”¯æŒå•æ–‡ä»¶,ä¸”æ–‡ä»¶å¤§å°<5GB) ----------
    @validate_call
    def upload_to_oss(
        self,
        token_data: dict,
        init_data: dict,
        file_path: str,
        *,
        show_progress: bool = True,
    ) -> dict:
        """ä¸Šä¼ æ–‡ä»¶åˆ° OSS

        Args:
            token_data:     get_token æ¥å£è¿”å›çš„ data å­—æ®µ
            init_data:      init/init_with_auto_sign æ¥å£è¿”å›çš„ JSON
            file_path:      æœ¬åœ°æ–‡ä»¶è·¯å¾„
            show_progress:  æ˜¯å¦æ˜¾ç¤ºä¸Šä¼ è¿›åº¦æ¡

        Returns:
            ä¸Šä¼ ç»“æœ,åªè¦ {"state": True, ...} å°±è¡¨ç¤ºä¸Šä¼ æˆåŠŸ

        """
        data = self._extract_data(init_data)
        bucket, obj = data.get("bucket"), data.get("object")
        if not (bucket and obj):
            raise ValueError(f"åˆå§‹åŒ–æ•°æ®ç¼ºå°‘ bucket/object: {data}")

        cbobj = data.get("callback", {})
        cb, cb_var = cbobj.get("callback"), cbobj.get("callback_var")
        if not all(isinstance(x, str) for x in (cb, cb_var)):
            raise ValueError(f"å›è°ƒå­—æ®µç¼ºå¤±æˆ–ç±»å‹é”™è¯¯: {cbobj}")

        cb_b64 = base64.b64encode(cb.encode()).decode()
        cb_var_b64 = base64.b64encode(cb_var.encode()).decode()

        endpoint = token_data["endpoint"]
        host = endpoint.split("://")[-1]
        region = host.split(".")[0].replace("oss-", "") if host else ""

        credentials_provider = oss.credentials.StaticCredentialsProvider(
            token_data["AccessKeyId"],
            token_data["AccessKeySecret"],
            token_data["SecurityToken"],
        )
        cfg = oss.config.load_default()
        cfg.credentials_provider = credentials_provider
        cfg.region = region
        client = oss.Client(cfg)

        # åˆ›å»ºè¿›åº¦å›è°ƒ
        progress_fn, bar = self._make_progress_fn(file_path, show_progress)

        result = client.put_object_from_file(
            oss.PutObjectRequest(
                bucket=bucket,  # å­˜å‚¨ç©ºé—´åç§°
                key=obj,  # å¯¹è±¡åç§°
                callback=cb_b64,
                callback_var=cb_var_b64,
                progress_fn=progress_fn,
            ),
            file_path,  # æœ¬åœ°æ–‡ä»¶è·¯å¾„
        )

        if bar:
            bar.close()
            print()

        result_dict = vars(result) if hasattr(result, "__dict__") else {}
        return {"state": True, "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ", "code": 200, "data": result_dict}

    # ---------- ä¸Šä¼ æ–‡ä»¶ ----------
    @validate_call
    def upload_file(
        self,
        file_name: str,
        file_size: int | None = None,
        target: str | int = "0",
        fileid: str | None = None,
        preid: str | None = None,
        pick_code: str | None = None,
        topupload: int | None = None,
        show_progress: bool = True,
    ) -> bool:
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ°115ç½‘ç›˜(ä»…æ”¯æŒå•ä¸ªæ–‡ä»¶ä¸Šä¼ ä¸”æ–‡ä»¶å¤§å°å°äº5GB)

        Args:
            file_name:      æ–‡ä»¶åæˆ–æœ¬åœ°æ–‡ä»¶è·¯å¾„
            file_size:      æ–‡ä»¶å¤§å°(å­—èŠ‚) (å¯é€‰, è‹¥ file_name æ˜¯æœ¬åœ°è·¯å¾„åˆ™å¯è‡ªåŠ¨è®¡ç®—)
            target:         æ–‡ä»¶ä¸Šä¼ ç›®æ ‡çº¦å®š, æ–‡ä»¶å¤¹ID (é»˜è®¤æ ¹ç›®å½•0)
            fileid:        æ–‡ä»¶sha1å€¼ (å¯é€‰, è‹¥ file_name æ˜¯æœ¬åœ°è·¯å¾„åˆ™å¯è‡ªåŠ¨è®¡ç®—)
            preid:        æ–‡ä»¶å‰128Ksha1 (å¯é€‰, è‹¥ file_name æ˜¯æœ¬åœ°è·¯å¾„åˆ™å¯è‡ªåŠ¨è®¡ç®—)
            pick_code:    ä¸Šä¼ ä»»åŠ¡key[éç§’ä¼ çš„è°ƒåº¦æ¥å£è¿”å›çš„pick_codeå­—æ®µ]
            topupload:    ä¸Šä¼ è°ƒåº¦æ–‡ä»¶ç±»å‹è°ƒåº¦æ ‡è®°
            show_progress: æ˜¯å¦æ˜¾ç¤ºä¸Šä¼ è¿›åº¦æ¡

        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ

        """
        resp_init = self.init_with_auto_sign(
            file_name=file_name,
            file_size=file_size,
            target=target,
            fileid=fileid,
            preid=preid,
            pick_code=pick_code,
            topupload=topupload,
        )
        item = self._extract_data(resp_init)
        status = item.get("status")

        # ç§’ä¼ æˆåŠŸ
        if status == 2:
            return True

        token_resp = self.get_token()
        token_data = token_resp.get("data") or {}

        resp = self.upload_to_oss(
            token_data=token_data,
            init_data=resp_init,
            file_path=file_name,
            show_progress=show_progress,
        )
        if resp.get("state"):
            return True

        return False

    def upload_folder(self, folder_path: str, target: str | int = "0", *, create_folder: bool = True, show_progress: bool = True) -> dict:
        """ä¸Šä¼ æ–‡ä»¶å¤¹(å•ä¸ªæ–‡ä»¶å¤§å°è¦å°äº5GB)

        å¤šçº¿ç¨‹ä¸Šä¼ æ–‡ä»¶å¤¹ï¼Œä¿æŒæœ¬åœ°ä¸äº‘ç«¯ç›®å½•ç»“æ„ä¸€è‡´

        Args:
            folder_path:   æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„
            target:        ç›®æ ‡æ–‡ä»¶å¤¹ID, é»˜è®¤æ ¹ç›®å½• '0'
            create_folder: æ˜¯å¦åœ¨ç›®æ ‡ä½ç½®åˆ›å»ºä¸æœ¬åœ°åŒåçš„æ–‡ä»¶å¤¹
            show_progress: æ˜¯å¦æ˜¾ç¤ºæ€»ä½“ä¸Šä¼ è¿›åº¦æ¡

        """
        folder = Path(folder_path)
        if not folder.is_dir():
            raise ValueError(f"{folder_path} ä¸æ˜¯æœ‰æ•ˆæ–‡ä»¶å¤¹")

        try:
            target_id = int(target)
        except (ValueError, TypeError) as e:
            raise ValueError(f"æ— æ•ˆçš„ç›®æ ‡æ–‡ä»¶å¤¹ID: {target}") from e

        # å¦‚æœéœ€è¦ï¼Œåˆ›å»ºæ–‡ä»¶å¤¹æœ¬èº«
        if create_folder:
            target_id = self._get_or_create_folder(target_id, folder.name)

        cloud_folder_cache = {"": target_id}
        cache_lock = Lock()
        cpus = os.cpu_count() or 1
        max_workers = max(1, cpus - 1)

        # ç¬¬ä¸€æ­¥ï¼šé¡ºåºåˆ›å»ºæ‰€æœ‰æ–‡ä»¶å¤¹
        all_items = sorted(folder.rglob("*"), key=lambda p: len(p.relative_to(folder).parts))
        folders = [p for p in all_items if p.is_dir()]
        files = [p for p in all_items if p.is_file()]

        for folder_path_item in folders:
            rel_path = folder_path_item.relative_to(folder)
            rel_path_str = str(rel_path)

            if rel_path_str in cloud_folder_cache:
                continue

            parent_rel_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""
            parent_id = cloud_folder_cache.get(parent_rel_path, target_id)

            folder_id = self._get_or_create_folder(parent_id, folder_path_item.name)
            cloud_folder_cache[rel_path_str] = folder_id

        # ç¬¬äºŒæ­¥ï¼šå¤šçº¿ç¨‹å¹¶å‘ä¸Šä¼ æ–‡ä»¶
        results = []

        def upload_single_file(local_path):
            """ä¸Šä¼ å•ä¸ªæ–‡ä»¶çš„å·¥ä½œå‡½æ•°"""
            try:
                rel_path = local_path.relative_to(folder)
                parent_rel_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""

                with cache_lock:
                    target_folder_id = cloud_folder_cache.get(parent_rel_path, target_id)

                # é™é»˜ä¸Šä¼ ï¼ˆå…³é—­æ‰€æœ‰è¿›åº¦æ¡å’Œæ—¥å¿—ï¼‰
                res = self.upload_file(
                    file_name=str(local_path),
                    target=int(target_folder_id),
                    show_progress=False,
                )

                return {
                    "local_path": str(local_path),
                    "relative_path": str(rel_path),
                    "cloud_folder_id": target_folder_id,
                    "result": res,
                    "success": True,
                }

            except Exception as e:
                return {
                    "local_path": str(local_path),
                    "relative_path": str(rel_path) if "rel_path" in locals() else "unknown",
                    "error": str(e),
                    "success": False,
                }

        # åˆ›å»ºæ€»ä½“è¿›åº¦æ¡
        overall_progress = (
            tqdm(
                total=len(files),
                desc="ğŸ“¦ ä¸Šä¼ ä¸­",
                unit="ä¸ª",
                leave=True,
            )
            if show_progress
            else None
        )

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_file = {executor.submit(upload_single_file, file_path): file_path for file_path in files}

            for future in as_completed(future_to_file):
                file_path = future_to_file[future]
                try:
                    result = future.result()
                    results.append(result)

                    if overall_progress:
                        # åœ¨è¿›åº¦æ¡å³è¾¹åŠ¨æ€æ˜¾ç¤ºå½“å‰å®Œæˆçš„æ–‡ä»¶
                        status = "âœ“" if result.get("success") else "âœ—"
                        rel_path = result.get("relative_path", file_path.name)
                        overall_progress.set_postfix_str(f"{status} {rel_path}")
                        overall_progress.update(1)

                except Exception as e:
                    results.append(
                        {
                            "local_path": str(file_path),
                            "relative_path": "unknown",
                            "error": str(e),
                            "success": False,
                        }
                    )
                    if overall_progress:
                        overall_progress.set_postfix_str(f"âœ— {file_path.name} (å¼‚å¸¸)")
                        overall_progress.update(1)

        if overall_progress:
            overall_progress.close()

        success_count = sum(1 for r in results if r.get("success"))
        failed_count = len(results) - success_count

        return {
            "state": True,
            "message": "ä¸Šä¼ å®Œæˆ",
            "code": 200,
            "total": len(results),
            "success": success_count,
            "failed": failed_count,
            "data": results,
        }

    @staticmethod
    def _extract_data(d: dict) -> dict:
        """ä»115è¿”å›çš„ JSON å“åº”ä¸­æå–é¦–ä¸ª data é¡¹"""
        data = d.get("data")
        if isinstance(data, list):
            data1 = data[0] if data else None
            return data1 if isinstance(data1, dict) else {}
        if isinstance(data, dict):
            return data
        return {}

    @staticmethod
    def _make_progress_fn(file_path: str, show_progress=True):
        """åˆ›å»ºä¸€ä¸ªè¿›åº¦å›è°ƒå‡½æ•° progress_fn(n, written, total)"""
        if not show_progress:
            return None, None

        total_size = Path(file_path).stat().st_size
        bar = None
        try:
            bar = tqdm(total=total_size, unit="B", unit_scale=True, desc="ä¸Šä¼ ", leave=False)

            def progress_fn(n: int, written: int, total: int):
                bar.update(n)

            return progress_fn, bar
        except Exception:
            return None, None

    def _get_all_files(self, parent_id: int, show_dir: int = 1) -> dict:
        """è·å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
        all_items = []
        offset = 0
        limit = 1150

        while True:
            resp = self.file.files(cid=parent_id, show_dir=show_dir, limit=limit, offset=offset)

            if not resp.get("state", False):
                raise RuntimeError(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {resp}")

            items = resp.get("data", [])
            if not items:
                break

            all_items.extend(items)
            count = resp.get("count", 0)
            if len(all_items) >= count or len(items) < limit:
                break

            offset += limit

        respjson = copy.deepcopy(resp)
        respjson["data"] = all_items
        return respjson

    @validate_call
    def _get_or_create_folder(self, parent_id: int, folder_name: str) -> int:
        """è·å–æˆ–åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆæ”¯æŒè¶…è¿‡1150ä¸ªæ–‡ä»¶çš„ç›®å½•ï¼‰"""
        if parent_id < 0:
            raise ValueError(f"æ— æ•ˆçš„çˆ¶æ–‡ä»¶å¤¹ID: {parent_id}")

        # æŸ¥æ‰¾åŒåæ–‡ä»¶å¤¹
        all_items = self._get_all_files(parent_id, show_dir=1).get("data", [])
        for item in all_items:
            if str(item.get("fc")) == "0" and str(item.get("fn")) == folder_name and str(item.get("pid")) == str(parent_id):
                folder_id = item.get("fid")
                if folder_id:
                    return int(folder_id)

        # åˆ›å»ºæ–°æ–‡ä»¶å¤¹
        create_resp = self.file.add(pid=parent_id, file_name=folder_name)

        if not create_resp.get("state", False):
            raise RuntimeError(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {create_resp}")

        new_folder_id = create_resp.get("file_id") or create_resp.get("data", {}).get("file_id")
        if not new_folder_id:
            raise RuntimeError("åˆ›å»ºæ–‡ä»¶å¤¹æˆåŠŸä½†æœªè¿”å›æ–‡ä»¶å¤¹ID")

        return int(new_folder_id)

    def upload_loop(
        self,
        folder_path: str,
        target: int | str = "0",
        *,
        create_folder: bool = True,
        show_progress: bool = False,
    ) -> dict:
        """å¾ªç¯ä¸Šä¼ æ–‡ä»¶å¤¹ï¼Œä¿æŒæœ¬åœ°ä¸äº‘ç«¯ç›®å½•ç»“æ„ä¸€è‡´

        æ¨èä½¿ç”¨ upload_folder æ–¹æ³•ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶å‘ä¸Šä¼ 

        Args:
            folder_path:   æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„
            target:        ç›®æ ‡æ–‡ä»¶å¤¹ID, é»˜è®¤æ ¹ç›®å½• '0'
            create_folder: æ˜¯å¦åœ¨ç›®æ ‡ä½ç½®åˆ›å»ºä¸æœ¬åœ°åŒåçš„æ–‡ä»¶å¤¹
            show_progress: æ˜¯å¦æ˜¾ç¤ºæ€»ä½“ä¸Šä¼ è¿›åº¦æ¡

        Returns:
            åŒ…å«æ¯ä¸ªæ–‡ä»¶ä¸Šä¼ ç»“æœçš„å­—å…¸
        """
        folder = Path(folder_path)
        if not folder.is_dir():
            raise ValueError(f"{folder_path} ä¸æ˜¯æœ‰æ•ˆæ–‡ä»¶å¤¹")

        try:
            target_id = int(target)
        except (ValueError, TypeError) as e:
            raise ValueError(f"æ— æ•ˆçš„ç›®æ ‡æ–‡ä»¶å¤¹ID: {target}") from e

        # å¦‚æœéœ€è¦ï¼Œåˆ›å»ºæ–‡ä»¶å¤¹æœ¬èº«
        if create_folder:
            target_id = self._get_or_create_folder(target_id, folder.name)

        # ç¼“å­˜äº‘ç«¯æ–‡ä»¶å¤¹è·¯å¾„
        cloud_folder_cache = {"": target_id}
        results = []

        # æŒ‰è·¯å¾„æ·±åº¦æ’åºï¼Œç¡®ä¿å…ˆåˆ›å»ºçˆ¶ç›®å½•
        all_files = sorted(folder.rglob("*"), key=lambda p: len(p.relative_to(folder).parts))

        for local_path in all_files:
            try:
                rel_path = local_path.relative_to(folder)

                if local_path.is_dir():
                    # å¤„ç†æ–‡ä»¶å¤¹
                    rel_path_str = str(rel_path)
                    if rel_path_str in cloud_folder_cache:
                        continue

                    parent_rel_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""
                    parent_id = cloud_folder_cache.get(parent_rel_path, target_id)

                    folder_id = self._get_or_create_folder(parent_id, local_path.name)
                    cloud_folder_cache[rel_path_str] = folder_id

                elif local_path.is_file():
                    # å¤„ç†æ–‡ä»¶
                    parent_rel_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""

                    # å¦‚æœçˆ¶ç›®å½•è¿˜æ²¡åœ¨ç¼“å­˜ä¸­ï¼Œé€’å½’åˆ›å»º
                    if parent_rel_path and parent_rel_path not in cloud_folder_cache:
                        current_parent_id = target_id
                        current_path = ""

                        for part in rel_path.parent.parts:
                            current_path = f"{current_path}/{part}" if current_path else part
                            if current_path not in cloud_folder_cache:
                                folder_id = self._get_or_create_folder(current_parent_id, part)
                                cloud_folder_cache[current_path] = folder_id
                                current_parent_id = folder_id
                            else:
                                current_parent_id = cloud_folder_cache[current_path]

                    target_folder_id = cloud_folder_cache.get(parent_rel_path, target_id)

                    # ä¸Šä¼ æ–‡ä»¶
                    res = self.upload_file(
                        file_name=str(local_path),
                        target=str(target_folder_id),
                        show_progress=show_progress,
                    )
                    results.append(
                        {
                            "local_path": str(local_path),
                            "relative_path": str(rel_path),
                            "cloud_folder_id": target_folder_id,
                            "result": res,
                            "success": True,
                        }
                    )

            except Exception as e:
                results.append(
                    {
                        "local_path": str(local_path),
                        "relative_path": str(rel_path) if "rel_path" in locals() else "unknown",
                        "error": str(e),
                        "success": False,
                    }
                )

        return {
            "state": True,
            "message": "ä¸Šä¼ å®Œæˆ",
            "code": 200,
            "total": len(results),
            "success": sum(1 for r in results if r.get("success")),
            "failed": sum(1 for r in results if not r.get("success")),
            "data": results,
        }

    @validate_call
    def upload(
        self,
        path: str,
        target: str | int = "0",
        *,
        create_folder: bool = True,
        show_progress: bool = True,
        **kwargs: Any,
    ) -> dict | bool:
        """è‡ªåŠ¨åˆ¤æ–­è·¯å¾„ç±»å‹å¹¶ä¸Šä¼ æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹

        æ ¹æ®è·¯å¾„è‡ªåŠ¨åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹ï¼Œå¹¶è°ƒç”¨ç›¸åº”çš„ä¸Šä¼ æ–¹æ³•ã€‚

        Args:
            path: æœ¬åœ°æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„
            target: ç›®æ ‡æ–‡ä»¶å¤¹IDï¼Œé»˜è®¤æ ¹ç›®å½• '0'
            create_folder: æ˜¯å¦åœ¨ç›®æ ‡ä½ç½®åˆ›å»ºä¸æœ¬åœ°åŒåçš„æ–‡ä»¶å¤¹ï¼ˆä»…æ–‡ä»¶å¤¹ä¸Šä¼ æ—¶æœ‰æ•ˆï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºä¸Šä¼ è¿›åº¦æ¡
            **kwargs: å…¶ä»–å‚æ•°ï¼Œé€ä¼ ç»™ upload_fileï¼ˆå¦‚ file_size, fileid, preid, pick_code, topuploadï¼‰

        Returns:
            - æ–‡ä»¶ä¸Šä¼ ï¼šè¿”å› boolï¼ˆTrue è¡¨ç¤ºæˆåŠŸï¼‰
            - æ–‡ä»¶å¤¹ä¸Šä¼ ï¼šè¿”å› dictï¼ˆåŒ…å«ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯ï¼‰

        Raises:
            ValueError: å½“è·¯å¾„ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®æ—¶

        Examples:
            >>> uploader = Uploader(auth)
            >>> # ä¸Šä¼ å•ä¸ªæ–‡ä»¶
            >>> uploader.upload("test.txt", target="0")
            True
            >>> # ä¸Šä¼ æ–‡ä»¶å¤¹
            >>> uploader.upload("my_folder", target="0", create_folder=True)
            {'state': True, 'message': 'ä¸Šä¼ å®Œæˆ', ...}
        """
        p = Path(path)

        if not p.exists():
            raise ValueError(f"è·¯å¾„ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {path}")

        # åˆ¤æ–­æ˜¯æ–‡ä»¶å¤¹è¿˜æ˜¯æ–‡ä»¶
        if p.is_dir():
            resp = self.upload_folder(
                folder_path=str(p),
                target=target,
                create_folder=create_folder,
                show_progress=show_progress,
            )
        elif p.is_file():
            # æå– upload_file æ”¯æŒçš„å‚æ•°
            resp = self.upload_file(
                file_name=str(p),
                file_size=kwargs.get("file_size"),
                target=target,
                fileid=kwargs.get("fileid"),
                preid=kwargs.get("preid"),
                pick_code=kwargs.get("pick_code"),
                topupload=kwargs.get("topupload"),
                show_progress=show_progress,
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è·¯å¾„ç±»å‹: {path}")
        return resp
